Weak convergence of the FMadogram estimator in presence of missing data.

Simulations to observe the behaviour of this estimator.

Updates :
--------

[o] Compute the variance of the gaussian process limit considering a FMadogram and independent copula (equal to 1/90).
[o] Generalize it with the lambda Madogram and independent copula
[x] Do the computation for the brownian bridge with missing data
[o] Consider other copula which are tractable to compute
[x] Make simulations for extreme value copulas
[ ] Find some condition under Pickhands dependence function such that the condition (iii) is verified.

1 - Update 27 / 05 / 2021 10 : 32

For the second bullet, the variance of the lambda Madogram take the closed form of :

g(x) = ((x^2)*(1-x)^2 / (1+x*(1-x))^2)) * ( 1 / (1+2*x*(1-x)) - (1-x) / (1 + x + 2*x*(1-x)) - x / (2 - x + 2*x*(1-x)))

where x is between 0 and 1.

Simulations have been added with lambda = 0.1, we plot the density as n (length of the sample) increase and added the density of the gaussian with
parameters 0 and g(0.1).

2 - Update 28 / 05 / 2021 9 : 22

Modifying latex (typos) and add some lines to detail the structure of the variance of the limiting process.

3 - Update 31 / 05 / 2021 17 : 26

Computations were done with missing data. Theory seems to not follow the results obtained by simulation... (especially for small value of lambda)

Notwithstanding, code was entirely reworked and a lot errors were handled. Theory was also reworked but no error was seen (i'm gonna write the proof clearly
hence you might be able to point out some theoretical error).

I'm starting the computations for extreme value copula, I can handle some computation easily but some might be harder.

4 - Update 02 / 06 / 2021 8 : 18

Add lemma in order to prove the functional integral that should satisfies each bounded measurable function with respect to a bounded variation function of the type
|x^\lambda - y^{1-\lambda}|.
We can prove, using the same tools, that the normalized estimator proposed in Naveau 2009 does not modify the variance of the limiting gaussian process.

5 - Update 08 / 08 / 2021 16 : 16

Code is now written in R. The same problem persist with n range from 2 to 1024. (see outputvar_lambda.pnh and outputvar_lambda_miss.png)
It works well without missing data but does not fit with missing data, as in python.

5 - Update 08 / 08 / 2021 16 : 42

Add some elements to compute covariance of the limiting process of Segers (2014).

6 - Update 11 / 06 / 2021 17:00 

Add a proof to show that my results were false on the convergence of the lambda FMadogram estimated
with missing data to a gaussian law with a certain variance (i'm still not sure about that). We can
see that remark 4 in Derumigny and Fermanian conditional empirical copula process (2020).

Compute a lower and an upper bound to the hard integral (12) the pdf.

7 - Update 14 / 06 / 2021 18 : 20

Add constant for variance of the lambda FMadogram when we consider an extreme value copula. I have bounded below the covariance (see the remark on the pdf).
I wasn't able to find an upper bound more beautiful. The constant are not really stylish, nevertheless, we (maybe) make them more beautiful at the cost of losing
precision.
Indeed, all the results are true until I found a mistake.

8 - Update 16 / 06 / 2021 18 : 51

Computations for the lower and upper bound are done with a extreme value copula (see pdf). I have drawn the two curve with respect
to lambda (see images variance_gumbell_0.15 and variance_galambos_copula_0.005). I have to estimate the lambda-FMadogram with simulated
data now. Then, enhance the writing of the tex file.

PS : The negative variance (=0 bc I took the max between the lower bound and 0) may come from an error in algebra. But I've checked may times
and I don't see any. Same for code.

PS2 : The upper bound cannot be equal to the variance of lambda-FMadogram when we took A(t) = 1 due to the positive sign of the covariance
between the brownian bridges and their partial derivative. In this contex, I can upper bound the covariance with the covariance
computed with the comonotonic copula and not the indepent (which is greater than 0).

9 - Update 17 / 06 / 2021 11:42

Big errors where found while computing the bounds of the covariance (I won't tell which ones because it is too shameful). They were fixed, and the bounds are
more coherent now.

10 - Update 17 / 06 / 2021 18:12

Add a code from scratch to simulate a Gumbel copula.

11 - Update 17 / 06 / 2021 19 : 33

Write the Monte Carlo simulation in a object oriented file in python.

12 - Update 18 / 06 / 2021 9:14

Typos were fixed on the derivative of the extreme value copula, the value of zeta is now modified.

13 - Update 18 / 06 / 2021 18:28

Added the code extreme_value_copula.py allows to do simulation with data with some dependencie (I have used 
the Gumbel Copula). Again, the results that I have does not support the theory (see extreme_value_copula.png in image file).
The problem : red curve is the lower bound (sometime negative), blue curve is independance variance, green curve is the upper bound
In salmon, our empirical variance. Sometimes the empirical variance are lower than the red dotted bound (unexpected)...
I'm checking the theory right now.
Then, the code.

14 - Update 22 / 06 / 2021 20 : 08

The pdf file was completely modified.
Add extreme_value_copula.R to simulate gumbel copula and estimate from these samples lambda Madogram.

15 - Update 23 / 06 / 2021 18 : 50

Add discussion on the value of Kappa and Zeta.

16 - Update 24 / 06 /2021 11 : 17

The code was checked. I have tried many Pickhands dependence function (Asymetric inverse negative logistic copula, Hussler-Reiss model). But 
the theory doesn't hold with simulation. 
I read back the theory mainly the proof of Lemma A.3. I have added some elements of argumentation (I have mainly use condition 3 (ii)
and also some properties of lebesgue integral.)
Nevertheless, I haven't find a mistake in there. All the difficult cases were tractable using our condition and properties of our object.
